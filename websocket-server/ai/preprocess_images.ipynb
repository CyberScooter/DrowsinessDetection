{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits images into closed and open eyes in two different folders using labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "\n",
    "new_path = os.path.join(\"C:/Users/hrithik/Documents/Projects/eyeImagesSeperated\", \"closed\")\n",
    "if not os.path.exists(new_path):\n",
    "    os.makedirs(new_path)\n",
    "\n",
    "new_path = os.path.join(\"C:/Users/hrithik/Documents/Projects/eyeImagesSeperated\", \"open\")\n",
    "if not os.path.exists(new_path):\n",
    "    os.makedirs(new_path)\n",
    "\n",
    "\n",
    "# options\n",
    "imgs = []\n",
    "foldersToBrowse = [\n",
    "    \"s0001\",\n",
    "    \"s0002\", \n",
    "    \"s0003\", \n",
    "    \"s0004\", \n",
    "    \"s0005\", \n",
    "    \"s0006\",\n",
    "    \"s0007\",\n",
    "    \"s0008\",\n",
    "    \"s0009\",\n",
    "    \"s0010\",\n",
    "    \"s0011\",\n",
    "    \"s0012\",\n",
    "    \"s0013\",\n",
    "    \"s0014\",\n",
    "    \"s0015\",\n",
    "    \"s0016\",\n",
    "    \"s0017\",\n",
    "    \"s0018\",\n",
    "    \"s0019\",\n",
    "    \"s0020\",\n",
    "    \"s0021\", \n",
    "    \"s0022\", \n",
    "    \"s0023\", \n",
    "    \"s0024\", \n",
    "    \"s0025\",\n",
    "    \"s0026\",\n",
    "    \"s0027\",\n",
    "    \"s0028\",\n",
    "    \"s0029\",\n",
    "    \"s0030\",\n",
    "    \"s0031\",\n",
    "    \"s0032\",\n",
    "    \"s0033\",\n",
    "    \"s0034\",\n",
    "    \"s0035\",\n",
    "    \"s0036\",\n",
    "    \"s0037\"\n",
    "]\n",
    "\n",
    "# opened = 1, closed = 0\n",
    "eyeState=1\n",
    "\n",
    "new_path=\"C:\\\\Users\\\\hrithik\\\\Documents\\\\Projects\\\\eyeImagesSeperated\"\n",
    "\n",
    "if(eyeState == 0):\n",
    "    new_path = os.path.join(new_path, \"closed\")\n",
    "elif(eyeState == 1):\n",
    "    new_path = os.path.join(new_path, \"open\")\n",
    "\n",
    "\n",
    "for i in foldersToBrowse:\n",
    "    folder_path= os.path.join('C:/Users/hrithik/Documents/Projects/mrlEyes_2018_01/mrlEyes_2018_01/', i)\n",
    "    images = [f for f in os.listdir(folder_path) if (os.path.isfile(os.path.join(folder_path, f)) and f.split(\"_\")[4] == str(eyeState))]\n",
    "    for image in images:\n",
    "        old_image_path = os.path.join(folder_path, image)\n",
    "        new_image_path = os.path.join(new_path, image)\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to extract drowsy images from images labelled as closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "folder_path= 'C:\\\\Users\\\\hrithik\\\\Documents\\\\Projects\\\\eyeImagesSeperated\\\\open'\n",
    "images = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "# reads image as grayscale\n",
    "\n",
    "\n",
    "\n",
    "# plt.imshow(imgs[3], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "import dlib\n",
    "\n",
    "# intialise dlib's pretrained face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# loads dlib pretrained facial landmarks to detector\n",
    "dlib_facelandmark = dlib.shape_predictor(\n",
    "    \"C:\\\\Users\\\\hrithik\\\\Documents\\\\Projects\\\\fyp-idea\\\\websocket-server\\\\ai\\\\shape_predictor_68_face_landmarks.dat\")\n",
    "# \n",
    "\n",
    "img = cv2.imread('C:\\\\Users\\\\hrithik\\\\Pictures\\\\img047.jpg') \n",
    "# img = cv2.imread(os.path.join('C:\\\\Users\\\\hrithik\\\\Documents\\\\Projects\\\\eyeImagesSeperated\\\\open', images[1])) \n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img_size = 224\n",
    "img_array = cv2.imread('C:\\\\Users\\\\hrithik\\\\Documents\\\\Projects\\\\eyeImagesSeperated\\\\closed\\\\s0001_00835_0_0_0_0_0_01.png',cv2.IMREAD_GRAYSCALE)\n",
    "backtorgb = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)\n",
    "new_array = cv2.resize(backtorgb, (img_size, img_size))\n",
    "X_input = np.array(new_array).reshape(1, img_size, img_size, 3)\n",
    "X_input = X_input/255.0\n",
    "\n",
    "new_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "prediction = new_model.predict(X_input)\n",
    "\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "if(prediction < 0.5):\n",
    "    print(\"Awake\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41946/41946 [15:45<00:00, 44.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os.path import join, dirname, realpath\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "dlib_facelandmark = dlib.shape_predictor(\n",
    "    \"C:\\\\Users\\\\hrithik\\\\Documents\\\\Projects\\\\fyp-idea\\\\websocket-server\\\\ai\\\\shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "folder_path= 'C:\\\\Users\\\\hrithik\\\\Documents\\\\Projects\\\\eyeImagesSeperated\\\\closed'\n",
    "images = [f for f in os.listdir(folder_path) if (os.path.isfile(os.path.join(folder_path, f)))]\n",
    "\n",
    "ear_values = []\n",
    "\n",
    "for i in tqdm(images):\n",
    "    leftEye = []\n",
    "    img = cv2.imread('face-of-peter-1433842.jpg')\n",
    "\n",
    "    img_to_place = cv2.imread(os.path.join(folder_path, i))\n",
    "\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray_to_place = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_h, img_w = gray.shape\n",
    "    img_to_place_h, img_to_place_w = gray_to_place.shape\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            resized_img = cv2.resize(img_to_place, (eh, ew), interpolation = cv2.INTER_AREA)\n",
    "            resized_img_h, resized_img_w, _ = resized_img.shape\n",
    "\n",
    "            roi_color[ey:ey+resized_img_h, ex:ex+resized_img_w, :] = resized_img\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # plt.figure()\n",
    "    # plt.imshow(gray, \"gray\")\n",
    "    # plt.show()  # display it\n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    face_landmarks = dlib_facelandmark(gray, faces[0])\n",
    "\n",
    "\n",
    "    for n in range(36, 42):\n",
    "        x = face_landmarks.part(n).x\n",
    "        y = face_landmarks.part(n).y\n",
    "        leftEye.append((x, y))\n",
    "        next_point = n+1\n",
    "        if n == 41:\n",
    "            next_point = 36\n",
    "        x2 = face_landmarks.part(next_point).x\n",
    "        y2 = face_landmarks.part(next_point).y\n",
    "        cv2.line(gray, (x, y), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "    left_ear = calculate_EAR(leftEye)\n",
    "    EAR = round(left_ear, 2)\n",
    "    ear_values.append([i, EAR])\n",
    "\n",
    "ear_values_output = pd.DataFrame(ear_values, columns=['id', 'EAR'])\n",
    "ear_values_output.to_csv('ear_values.csv', index=False)\n",
    "\n",
    "# cv2.imwrite(\"out.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "img = cv2.imread('C:\\\\Users\\\\hrithik\\\\Documents\\\\Projects\\\\eyeImagesSeperated\\\\closed\\\\s0001_00835_0_0_0_0_0_01.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "eye = eye_cascade.detectMultiScale(img)\n",
    "\n",
    "print(eye)\n",
    "\n",
    "# for (x,y,) in eye:\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_EAR(eye):\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    ear_aspect_ratio = (A+B)/(2.0*C)\n",
    "    return ear_aspect_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "# intialise dlib's pretrained face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# loads dlib pretrained facial landmarks to detector\n",
    "dlib_facelandmark = dlib.shape_predictor(\n",
    "    \"C:\\\\Users\\\\hrithik\\\\Documents\\\\Projects\\\\fyp-idea\\\\websocket-server\\\\ai\\\\shape_predictor_68_face_landmarks.dat\")\n",
    "# \n",
    "\n",
    "\n",
    "def calculate_EAR(eye):\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    ear_aspect_ratio = (A+B)/(2.0*C)\n",
    "    return ear_aspect_ratio\n",
    "\n",
    "\n",
    "folder_path= 'C:\\\\Users\\\\hrithik\\\\Documents\\\\Projects\\\\eyeImagesSeperated\\\\closed'\n",
    "images = [f for f in os.listdir(folder_path) if (os.path.isfile(os.path.join(folder_path, f)))]\n",
    "for image in images:\n",
    "    faces = replaceFace(os.path.join(folder_path, image))\n",
    "\n",
    "    for face in faces:\n",
    "        face_landmarks = dlib_facelandmark(gray, face)\n",
    "        leftEye = []\n",
    "        rightEye = []\n",
    "\n",
    "        for n in range(36, 42):\n",
    "            x = face_landmarks.part(n).x\n",
    "            y = face_landmarks.part(n).y\n",
    "            leftEye.append((x, y))\n",
    "            next_point = n+1\n",
    "            if n == 41:\n",
    "                next_point = 36\n",
    "            x2 = face_landmarks.part(next_point).x\n",
    "            y2 = face_landmarks.part(next_point).y\n",
    "            cv2.line(gray, (x, y), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "        for n in range(42, 48):\n",
    "            x = face_landmarks.part(n).x\n",
    "            y = face_landmarks.part(n).y\n",
    "            rightEye.append((x, y))\n",
    "            next_point = n+1\n",
    "            if n == 47:\n",
    "                next_point = 42\n",
    "            x2 = face_landmarks.part(next_point).x\n",
    "            y2 = face_landmarks.part(next_point).y\n",
    "            cv2.line(gray, (x, y), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "        left_ear = calculate_EAR(leftEye)\n",
    "\n",
    "        EAR = left_ear\n",
    "        EAR = round(EAR, 2)\n",
    "        print(EAR)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ee1ad421c1f20085a548d019e1a7a80b98920bae81f41e4d99874d382ca730e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
